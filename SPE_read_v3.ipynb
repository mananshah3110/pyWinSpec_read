{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# .SPE Read/Analyse"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-04-29T15:22:40.562043Z",
          "iopub.status.busy": "2020-04-29T15:22:40.561052Z",
          "iopub.status.idle": "2020-04-29T15:22:40.567736Z",
          "shell.execute_reply": "2020-04-29T15:22:40.565742Z",
          "shell.execute_reply.started": "2020-04-29T15:22:40.562043Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __version__ = 3.00\n",
        "- __author__ = Manan Shah\n",
        "\n",
        "\n",
        "--------------------------------------------- **Nomenclature** ---------------------------------------------\n",
        "\n",
        "- aa; bb; cc;.... # counters\n",
        "- ClassName\n",
        "- Exception_Name\n",
        "- function_name\n",
        "- function_parameter_name\n",
        "- GLOBAL_CONSTANT_NAME\n",
        "- global_Var_Name\n",
        "- instance_var_name\n",
        "- local_var_name\n",
        "- _method_name\n",
        "- module_name\n",
        "- package_name"
      ],
      "metadata": {
        "comments": [
          {
            "body": [
              {
                "created": "2020-05-23T08:26:08.846Z",
                "creator": {
                  "image": "https://avatars2.githubusercontent.com/u/290664?v=4",
                  "name": "manan",
                  "user": "Manan"
                },
                "edited": false,
                "value": "Metadata and the nomenclature used in the following program. I am afraid it's not strictly followed so far!"
              }
            ],
            "id": "anno/1",
            "resolved": false,
            "total": 1
          }
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk  # A robust and platform independent windowing toolkit to implement GUI.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# from IPython.display import SVG\n",
        "# from IPython.display import Image as IM\n",
        "from IPython.display import Markdown as MD\n",
        "from IPython.display import display\n",
        "from pathlib import Path\n",
        "from tkinter.filedialog import askopenfilenames, askopenfiles\n",
        "from pandas import DataFrame as DF\n",
        "from pint import UnitRegistry  # Assign units to qunatities\n",
        "\n",
        "# u = UnitRegistry(auto_reduce_dimensions=True) right syntax but not sure why not needed!\n",
        "u = UnitRegistry()  \n",
        "# \"~\": abbreviation of quantity (e.g. meter -> m) and \"P\": Physical quantity format (e.g. meter / second**2 -> meter/second^2)\n",
        "u.default_format = \"~P\"\n",
        "Q_ = u.Quantity\n",
        "\n",
        "from scipy import ndimage, signal\n",
        "from scipy.ndimage import (\n",
        "    convolve,\n",
        "    gaussian_filter,\n",
        "    gaussian_filter1d,\n",
        "    gaussian_laplace,\n",
        "    maximum,\n",
        "    maximum_filter,\n",
        "    maximum_filter1d,\n",
        "    maximum_position,\n",
        "    median_filter,\n",
        "    minimum,\n",
        "    minimum_filter,\n",
        "    minimum_filter1d,\n",
        "    minimum_position,\n",
        "    percentile_filter,\n",
        "    standard_deviation,\n",
        "    sum,\n",
        "    uniform_filter,\n",
        "    uniform_filter1d,\n",
        "    variance,\n",
        ")\n",
        "\n",
        "from scipy.signal import (\n",
        "    convolve,\n",
        "    detrend,\n",
        "    filtfilt,\n",
        "    find_peaks,\n",
        "    lfilter,\n",
        "    medfilt,\n",
        "    medfilt2d,\n",
        "    order_filter,\n",
        "    peak_prominences,\n",
        "    peak_widths,\n",
        "    resample,\n",
        "    resample_poly,\n",
        "    savgol_filter,\n",
        "    sosfilt,\n",
        "    symiirorder1,\n",
        "    symiirorder2,\n",
        "    upfirdn,\n",
        "    wiener,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:26.876233Z",
          "iopub.status.busy": "2020-10-07T14:39:26.876233Z",
          "iopub.status.idle": "2020-10-07T14:39:27.058129Z",
          "shell.execute_reply": "2020-10-07T14:39:27.058129Z",
          "shell.execute_reply.started": "2020-10-07T14:39:26.876233Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User defined functions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format display text"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def printmd(string, color=None):\n",
        "    \"\"\"\n",
        "    Displays the string in color with markdown effects.\n",
        "\n",
        "        Parameters:\n",
        "            string (str): \"The string to be printed.\"\n",
        "            color (str): \"Color of the string (e.g., \"green\", \"red\").\"\n",
        "\n",
        "        Display:\n",
        "            display(MD(colorstr)): A colored string with markdown effects.\n",
        "\n",
        "        Example: printmd(f\"**the value: {a}**\", color = \"green\")\n",
        "    \"\"\"\n",
        "\n",
        "    colorstr = \"<span style='color:{}'>{}</span>\".format(\n",
        "        color,\n",
        "        string,\n",
        "    )\n",
        "    display(MD(colorstr))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:31.913166Z",
          "iopub.status.busy": "2020-10-07T14:39:31.912167Z",
          "iopub.status.idle": "2020-10-07T14:39:31.917164Z",
          "shell.execute_reply": "2020-10-07T14:39:31.916167Z",
          "shell.execute_reply.started": "2020-10-07T14:39:31.913166Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def import_files(ftype, fextension, dialogue_title):\n",
        "    \"\"\"\n",
        "    Import files of a specific type via a dialogue box.\n",
        "\n",
        "        Parameters:\n",
        "           ftype (str): File type (e.g. .SPE Files).\n",
        "           fextension (str): File extension (e.g. \".*spe\").\n",
        "           dialogue_title (str): Title of the dialogue box (e.g. \"Import files\").\n",
        "\n",
        "        Functions:\n",
        "            askopenfilenames(parent=root, filetypes=[(ftype, fextension,)], title=dialogue_title): Creates a modal, native look-and-feel dialog, wait for the user’s selection, then return the selected filename(s) that correspond to existing file(s). \n",
        "            pathlib.Path(): Offers classes representing filesystem paths with semantics appropriate for different operating systems.\n",
        "\n",
        "        Returns:\n",
        "            file_names: file_names (file objects) are fed to self.fnames in class File where they'll be read one by one.)\n",
        "\n",
        "        Example: import_files(self, ftype = \".SPE files\", fextension = \".*spe\", dialogue_title = \"Import .SPE files\")\n",
        "\n",
        "        Pattern | Meaning\n",
        "           *    | matches everything\n",
        "           ?    | matches any single character\n",
        "         [seq]  | matches any character in seq\n",
        "         [!seq] | matches any character not in seq\n",
        "\n",
        "         For a literal match, wrap the meta-characters in brackets. For example, '[?]' matches the character '?'\n",
        "    \"\"\"\n",
        "\n",
        "    root = tk.Tk()\n",
        "    file_names = askopenfilenames(\n",
        "        parent=root,\n",
        "        filetypes=[\n",
        "            (\n",
        "                ftype,\n",
        "                fextension,\n",
        "            )\n",
        "        ],\n",
        "        title=dialogue_title,\n",
        "    )\n",
        "    root.destroy()  # Destroy the window after the action is taken.\n",
        "\n",
        "    # .resolve() resolves the symlinks and eliminate “..” components to walk an arbitrary filesystem path upwards.\n",
        "    file_full_path = Path(file_names[0]).resolve()  \n",
        "    importDir = file_full_path.parent\n",
        "    printmd(f\"**Import directory : {importDir}**\", \"orange\")\n",
        "    printmd(f\"**No. of file(s) selected : {len(file_names)}**\\n\", \"orange\")\n",
        "    display(MD(\"**File(s) information**\"))\n",
        "\n",
        "    return file_names"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:33.603576Z",
          "iopub.status.busy": "2020-10-07T14:39:33.602576Z",
          "iopub.status.idle": "2020-10-07T14:39:33.608573Z",
          "shell.execute_reply": "2020-10-07T14:39:33.608573Z",
          "shell.execute_reply.started": "2020-10-07T14:39:33.603576Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read from a file"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def read_at(file, position, size, dtype):\n",
        "    \"\"\"\n",
        "    Returns data from a text or binary file starting at a particular position for a given size and specified data-type.\n",
        "\n",
        "        Parameters:\n",
        "           file (file object): Opens a single file object or a filename. (e.g. here .SPE file in a binary mode).\n",
        "           position (int): move the reading cursor characters ahead.\n",
        "           size (int): Number of items to read. -1 means all items (i.e., the complete file).\n",
        "           dtype (data type object): A data type object (an instance of numpy.dtype class) describes how the bytes in the                fixed-size block of memory corresponding to an array item should be interpreted. It describes the following                  aspects of the data:\n",
        "               1. Type of the data (integer, float, Python object, etc.)\n",
        "               2. Size of the data (how many bytes is in e.g. the integer)\n",
        "               3. Byte order of the data (little-endian or big-endian)\n",
        "               4. If the data type is structured data type, an aggregate of other data types (e.g. describing an array item                     consisting of an integer and a float).\n",
        "\n",
        "        Functions:\n",
        "            file.seek(position): Set the current read/write position. (e.g. file.seek(offset = position, from = 0 (0 =                                        beginning, 1 = current, 2 = end)))\n",
        "            np.fromfile(file, dtype, size):  A highly efficient way of reading binary data with a known data-type\n",
        "            \n",
        "            NOTE: Do not rely on the combination of tofile and fromfile for data storage, as the binary files generated are               not platform independent. In particular, no byte-order or data-type information is saved. Data can be stored in               the platform independent .npy format using save and load instead.\n",
        "\n",
        "        Returns:\n",
        "            np.fromfile(file, dtype, size): Construct an array from data in a text or binary file.\n",
        "\n",
        "        Example: read_at(file_obj, position = 23, size = 8, ntype = np.float32)\n",
        "    \"\"\"\n",
        "    \n",
        "    file.seek(position)  # set the current read/write position.\n",
        "    return np.fromfile(file, dtype, size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:34.695573Z",
          "iopub.status.busy": "2020-10-07T14:39:34.694572Z",
          "iopub.status.idle": "2020-10-07T14:39:34.698570Z",
          "shell.execute_reply": "2020-10-07T14:39:34.698570Z",
          "shell.execute_reply.started": "2020-10-07T14:39:34.695573Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Reverse"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def data_reverse(data):\n",
        "    \"\"\"\n",
        "    Returns an ndarray reversed from left to right to the original one. This funcation accepts only an array with >= 2D. In       order to do so, all the X- axis and data arrays are transformed into a matrix with atleast the shape of (1, xPixels).\n",
        "\n",
        "    Parameters:\n",
        "        data (ndarray): atleast 2D array.\n",
        "\n",
        "    Functions:\n",
        "        np.empty(shape, dtype=float, order='C'): Return a new array of given shape and type, without initializing entries.\n",
        "        np.fliplr(m {Input array, must be at least 2-D.}): Flip the entries in each row in the left/right direction.\n",
        "                                                           Columns are preserved, but appear in a different order than                                                                  before.\n",
        "\n",
        "    Returns:\n",
        "        data_reverse (ndarray): ndarray  with the same shape as of the input ndarray.\n",
        "    \"\"\"\n",
        "\n",
        "    index = 0\n",
        "    data_reverse = np.empty(shape=np.shape(data))\n",
        "\n",
        "    for aa in data:\n",
        "        data_reverse[index] = np.fliplr(aa)\n",
        "        index += 1\n",
        "\n",
        "    if np.shape(data) == np.shape(data_reverse):\n",
        "        printmd(\n",
        "            f\"The data is reversed and returned as {type(data_reverse)} with the same shape of {np.shape(data_reverse)}.\"\n",
        "        )\n",
        "        return data_reverse\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            \"The shape of data and reversed data does not match! Pls. make sure that the input- data has at least 2D.\"\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:35.888301Z",
          "iopub.status.busy": "2020-10-07T14:39:35.887302Z",
          "iopub.status.idle": "2020-10-07T14:39:35.893298Z",
          "shell.execute_reply": "2020-10-07T14:39:35.893298Z",
          "shell.execute_reply.started": "2020-10-07T14:39:35.888301Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Region selection and Binning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def region_bin(data, no_regns, stpts, endpts):\n",
        "    \"\"\"\n",
        "    Returns (2D) selected regions of a parent matrix as well as the binned 1D matrices of the corresponding selected regions.\n",
        "    It accepts the start/end points as a list.\n",
        "\n",
        "    NOTE: The shape of data_regn should be (no_regns,) because the selected regions might have diferent matrix size.\n",
        "\n",
        "    Parameters:\n",
        "        data (list, ndarray): A 2D array from which an inerested region is going to be selected.\n",
        "        no_regions (int): A positive integer to select the number of regions from the given 2D matrix.\n",
        "        stpts (list): A list of starting points for interested regions.\n",
        "        endpts (list): A list of ending points for interested regions.\n",
        "\n",
        "    Returns:\n",
        "        data_regn (list): List of ndarrays of sliced regions.\n",
        "        data_regn_binned (ndarray): ndarray of binned corresponding sliced regions.\n",
        "    \"\"\"\n",
        "\n",
        "    if no_regns == len(stpts) == len(endpts) or np.shape(data) > (1, 1):\n",
        "        printmd(f\"No. of regions selected = {no_regns}\")\n",
        "\n",
        "        data_regn = []\n",
        "        data_regn_binned = []\n",
        "\n",
        "        for aa in range(no_regns):\n",
        "            data_regn.append(data[stpts[aa] : endpts[aa]])\n",
        "            printmd(\"\\n\")\n",
        "            printmd(f\"Region {aa} [Start, End) = [{stpts[aa]} : {endpts[aa]})\")\n",
        "            printmd(f\"Shape of region {aa} = {np.shape(data_regn[aa])}\")\n",
        "\n",
        "            data_regn_bin = np.reshape(\n",
        "                data_regn[aa].sum(axis=0) / (endpts[aa] - stpts[aa]),\n",
        "                (1, np.shape(data_regn[aa])[1]),\n",
        "            )\n",
        "            data_regn_binned.append(data_regn_bin)\n",
        "            printmd(f\"Shape of binned region {aa} = {np.shape(data_regn_binned[aa])}\")\n",
        "\n",
        "        return data_regn, np.asanyarray(data_regn_binned)\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            \"The no. of regions and corresponding no. of start/end points do not match! Or the selected data is not 2D!\"\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:37.090743Z",
          "iopub.status.busy": "2020-10-07T14:39:37.089743Z",
          "iopub.status.idle": "2020-10-07T14:39:37.097739Z",
          "shell.execute_reply": "2020-10-07T14:39:37.097739Z",
          "shell.execute_reply.started": "2020-10-07T14:39:37.090743Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Differentiation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def differentiation(data, x):\n",
        "    \"\"\"\n",
        "    Returns a list of derivatetive of data w.r.t \"x\". This funcation accepts only an array with >= 2-Dimnesions.\n",
        "\n",
        "    Parameters:\n",
        "        data (ndarray): atleast 2D array.\n",
        "        x (ndarray): atleast 2D array.:\n",
        "\n",
        "    Returns:\n",
        "        derivative (list): List of ndarray(s) with the shape of the input list of ndarray(s) - no. of rows.\n",
        "    \"\"\"\n",
        "\n",
        "    dy = []\n",
        "    dx = []\n",
        "    derivative = []\n",
        "\n",
        "    if np.shape(data[0])[1] == np.shape(x[0])[1]:\n",
        "        for aa in range(len(data)):\n",
        "            dy.append(np.diff(data[aa]))  # dy\n",
        "            dx.append(np.diff(x[aa]))  # dx\n",
        "            derivative.append(np.divide(dy[aa], dx[aa])            )\n",
        "            printmd(f\"Shape of derivated data{aa} = {np.shape(derivative[aa])}\")\n",
        "\n",
        "        printmd(f\"The differentiation of the data w.r.t. 'x' is done.\")\n",
        "        return derivative\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"The shape of data {np.shape(data[0])} and 'x' {np.shape(x[0])} does not match!\"\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:39:38.428181Z",
          "iopub.status.busy": "2020-10-07T14:39:38.427182Z",
          "iopub.status.idle": "2020-10-07T14:39:38.433179Z",
          "shell.execute_reply": "2020-10-07T14:39:38.433179Z",
          "shell.execute_reply.started": "2020-10-07T14:39:38.428181Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reflection contrast"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def reflection_contrast(sam_data, sub_data):\n",
        "    \"\"\"\n",
        "    Returns the reflection contrast from selected (binned) regions.\n",
        "\n",
        "    Parameters:\n",
        "        sam_data (ndarray): An array of reflection intensity from sample.\n",
        "        sub_data (ndarray): An array of reflection intensity from substrate.\n",
        "\n",
        "    Returns:\n",
        "        reflection_contrast1 (list): list of (array(s) of) reflection contrast calucated using methode 1 (or 2).\n",
        "    \"\"\"\n",
        "\n",
        "    if np.shape(sam_data[0]) == np.shape(sub_data[0]):\n",
        "        printmd(f\"No. of (binned) regions selected = {len(sam_data)}\")\n",
        "\n",
        "        reflection_contrast1 = []\n",
        "        reflection_contrast2 = []\n",
        "\n",
        "        for aa in range(len(sam_data)):\n",
        "            reflection_contrast1.append((sam_data[aa] - sub_data[aa]) / sub_data[aa]) \n",
        "            printmd(f\"Shape of RC region {aa} = {np.shape(reflection_contrast1[aa])}\")\n",
        "\n",
        "        return reflection_contrast1  # or reflection_contrast2\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"The shape of sample {np.shape(sam_data[0])} and substrate {np.shape(sub_data[0])} does not match!\"\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:03.472336Z",
          "iopub.status.busy": "2020-10-07T14:40:03.472336Z",
          "iopub.status.idle": "2020-10-07T14:40:03.477335Z",
          "shell.execute_reply": "2020-10-07T14:40:03.477335Z",
          "shell.execute_reply.started": "2020-10-07T14:40:03.472336Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def mvg_window_fltr(data, window_type, mode, **kwargs):\n",
        "    \"\"\"\n",
        "    Returns filtered data by convoluting input data with a chosen moving window.\n",
        "\n",
        "    Parameters:\n",
        "        data (ndarray): input ndarrray vector. It must be a 2D array.\n",
        "        window_type (tupple with respective arguments): 'Window name' (string) tuppled with 'positional argument(s)'                                                                  respective to that particular window.\n",
        "        mode (string {optional}): (reflect, constant, nearest, mirror, wrap); The mode parameter determines how the input                                       array is extended beyond its boundaries. Default is ‘reflect’. Behavior for each valid                                       value is as follows:\n",
        "                                  ‘reflect’ (d c b a | a b c d | d c b a) The input is extended by reflecting about the edge                                   of the last pixel.\n",
        "                                  ‘constant’ (k k k k | a b c d | k k k k) The input is extended by filling all values beyond                                    the edge with the same constant value, defined by the cval parameter.\n",
        "                                  ‘nearest’ (a a a a | a b c d | d d d d) The input is extended by replicating the last                                          pixel.\n",
        "                                  ‘mirror’ (d c b | a b c d | c b a) The input is extended by reflecting about the center of                                    the last pixel.\n",
        "                                  ‘wrap’ (a b c d | a b c d | a b c d) The input is extended by wrapping around to the                                          opposite edge.\n",
        "        cval (scalar {optional}): Value to fill past edges of input if mode is ‘constant’. Default is 0.\n",
        "        origin (int or sequence {optional}): Controls the placement of the filter on the input array’s pixels. A value of 0                                                (default) centers the filter over the pixel, with positive values shifting the                                                filter to the left, and negative ones to the right. By passing a sequence of                                                  origins with length equal to the number of dimensions of the input array,                                                    different shifts can be specified along each axis.\n",
        "\n",
        "    Returns:\n",
        "        data_fltrd (ndarray): The convolved array of the input array.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"    \n",
        "        # Original window dictionary ffrom scipy.signal.windows souce code\n",
        "        windowsAll_dict = {  \n",
        "            ('barthann', 'brthan', 'bth'): signal.barthann,\n",
        "            ('bartlett', 'bart', 'brt'): signal.bartlett, \n",
        "            ('blackman', 'black', 'blk'): (signal.blackman), \n",
        "            ('blackmanharris', 'blackharr', 'bkh'): signal.blackmanharris, \n",
        "            ('bohman', 'bman', 'bmn'): signal.bohman, \n",
        "            ('boxcar', 'box', 'ones', 'rect', 'rectangular', 'mvg avg', 'mvg_avg', 'uniform', 'flat'): signal.boxcar, \n",
        "            ('chebwin', 'cheb'): signal.chebwin, \n",
        "            ('cosine', 'halfcosine'): signal.cosine,\n",
        "            ('exponential', 'poisson'): signal.exponential, \n",
        "            ('flattop', 'flat', 'flt'): (signal.flattop), \n",
        "            ('gaussian', 'gauss', 'gss'): signal.gaussian, \n",
        "            ('general cosine', 'general_cosine'): signal.windows.general_cosine,\n",
        "            ('general gaussian', 'general_gaussian', 'general gauss', 'general_gauss', 'ggs'): signal.general_gaussian, \n",
        "            ('general hamming', 'general_hamming'): signal.windows.general_hamming,\n",
        "            ('hamming', 'hamm', 'ham'): signal.hamming, \n",
        "            ('hanning', 'hann', 'han'): signal.hann, \n",
        "            ('kaiser', 'ksr'): signal.kaiser, \n",
        "            ('medfilt', 'median filt'): signal.medfilt, \n",
        "            ('nuttall', 'nutl', 'nut'): signal.nuttall, \n",
        "            ('parzen', 'parz', 'par'): signal.parzen, \n",
        "            ('savgol coeffs' ,'savgol_coeffs'): signal.savgol_coeffs,\n",
        "            ('slepian', 'slep', 'optimal', 'dpss', 'dss'): signal.slepian, \n",
        "            ('triangle', 'triang', 'tri'): signal.triang,  \n",
        "            ('tukey', 'tuk'): signal.tukey,  \n",
        "            (): ndimage.uniform_filter1d} \n",
        "    \"\"\"\n",
        "\n",
        "    windowsAll_tuple = (\n",
        "        ((\"barthann\", \"brthan\", \"bth\"), signal.barthann),\n",
        "        ((\"bartlett\", \"bart\", \"brt\"), signal.bartlett),\n",
        "        ((\"blackman\", \"black\", \"blk\"), signal.blackman),\n",
        "        ((\"blackmanharris\", \"blackharr\", \"bkh\"), signal.blackmanharris),\n",
        "        ((\"bohman\", \"bman\", \"bmn\"), signal.bohman),\n",
        "        (\n",
        "            (\n",
        "                \"boxcar\",\n",
        "                \"box\",\n",
        "                \"ones\",\n",
        "                \"rect\",\n",
        "                \"rectangular\",\n",
        "                \"mvg avg\",\n",
        "                \"mvg_avg\",\n",
        "                \"uniform\",\n",
        "                \"flat\",\n",
        "                \"avg\",\n",
        "            ),\n",
        "            signal.boxcar,\n",
        "        ),\n",
        "        ((\"chebwin\", \"cheb\"), signal.chebwin),\n",
        "        ((\"cosine\", \"halfcosine\"), signal.cosine),\n",
        "        ((\"exponential\", \"poisson\"), signal.exponential),\n",
        "        ((\"flattop\", \"flt\"), signal.flattop),\n",
        "        ((\"gaussian\", \"gauss\", \"gss\"), signal.gaussian),\n",
        "        ((\"general cosine\", \"general_cosine\"), signal.windows.general_cosine),\n",
        "        (\n",
        "            (\n",
        "                \"general gaussian\",\n",
        "                \"general_gaussian\",\n",
        "                \"general gauss\",\n",
        "                \"general_gauss\",\n",
        "                \"ggs\",\n",
        "            ),\n",
        "            signal.general_gaussian,\n",
        "        ),\n",
        "        ((\"general hamming\", \"general_hamming\"), signal.windows.general_hamming),\n",
        "        ((\"hamming\", \"hamm\", \"ham\"), signal.hamming),\n",
        "        ((\"hanning\", \"hann\", \"han\"), signal.hann),\n",
        "        ((\"kaiser\", \"ksr\"), signal.kaiser),\n",
        "        ((\"medfilt\", \"median filt\"), signal.medfilt),\n",
        "        ((\"nuttall\", \"nutl\", \"nut\"), signal.nuttall),\n",
        "        ((\"parzen\", \"parz\", \"par\"), signal.parzen),\n",
        "        ((\"savgol coeffs\", \"savgol_coeffs\"), signal.savgol_coeffs),\n",
        "        ((\"slepian\", \"slep\", \"optimal\", \"dpss\", \"dss\"), signal.slepian),\n",
        "        ((\"triangle\", \"triang\", \"tri\"), signal.triang),\n",
        "        ((\"tukey\", \"tuk\"), signal.tukey),\n",
        "    )\n",
        "\n",
        "    # convert tupples into a modified dictionary where tuppled keys are untuppled and correspond to the same value. e.g. {'a': 1, 'b':1, 'c':2} instead of {(a,b):1, ('c'):2}\n",
        "    windowsAll_dict_mod = {\n",
        "        key: value for keys, value in windowsAll_tuple for key in keys\n",
        "    }\n",
        "\n",
        "    if data.ndim == 2:\n",
        "        printmd(f\"Input vector shape: {np.shape(data)}\")\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"The data {np.shape(data[0])} should be comprise of either 1D matrix or 2D array.\"\n",
        "        )\n",
        "\n",
        "    if isinstance(window_type, tuple):\n",
        "        window_str = window_type[0]\n",
        "        args = window_type[1:]\n",
        "\n",
        "        # Returns a list containing the dictionary's keys\n",
        "        if window_str in windowsAll_dict_mod.keys():\n",
        "            printmd(f\"Filter window type: {window_str}.\")\n",
        "            printmd(f\"{len(args)} additional argument(s): {args}\")\n",
        "\n",
        "        else:\n",
        "            while True:\n",
        "                try:\n",
        "                    window_type = eval(\n",
        "                        input(\n",
        "                            f\"Pls. enter the window type (e.g. ('general_gaussian', *args)): \"\n",
        "                        )\n",
        "                    )  # Evaluate string as a tuple.\n",
        "                    window_str = window_type[0]\n",
        "                    args = window_type[1:]\n",
        "\n",
        "                    if (window_str in windowsAll_dict_mod.keys()) and len(window_type) > 1:\n",
        "                        printmd(\"length:\", len(window_type))\n",
        "                        printmd(f\"Entered window type: {window_str}\")\n",
        "                        printmd(f\"Entered {len(args)} additional argument(s): {args}\")\n",
        "\n",
        "                    else:\n",
        "                        raise ValueError\n",
        "\n",
        "                except ValueError:\n",
        "                    printmd(\n",
        "                        f\"Entered {window_str} window does not match with the available window types. Available windows are: {windows_all_mod}\"\n",
        "                    )\n",
        "                    continue\n",
        "\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        wind_func = windowsAll_dict_mod.get(\n",
        "            window_str\n",
        "        )  # Returns the value of the specified key\n",
        "        w = wind_func(*args)  # Window wieghts\n",
        "        norm_window = w / sum(w)\n",
        "\n",
        "        printmd(f\"Window: {norm_window}\")\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            \"Please enter a window_type and it's parameters in a tuple form (e.g. ('general_gaussian, 1, 7) or ('flat', 5)'.\"\n",
        "        )\n",
        "\n",
        "    if round(sum(norm_window), 2) == 1:\n",
        "        printmd(f\"Sum of window elements: {sum(norm_window)}\")\n",
        "\n",
        "        data_fltrd = []\n",
        "        for aa in range(len(data)):\n",
        "            data_fltrd.append(\n",
        "                ndimage.convolve(input=data[aa], weights=norm_window, mode=mode)\n",
        "            )\n",
        "\n",
        "        if np.shape(data) == np.shape(np.asanyarray(data_fltrd)):\n",
        "            printmd(\n",
        "                f\"The data is smoothed with a normalized window and returned with same shape of {np.shape(np.asanyarray(data_fltrd))}\"\n",
        "            )\n",
        "            return np.asanyarray(data_fltrd)\n",
        "        else:\n",
        "            raise Exception(\n",
        "                f\"The shape of input data {np.shape(data)} does not match with the filtered data {np.shape(np.asanyarray(data_fltrd))}.\"\n",
        "            )\n",
        "\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Them sum of the window elements is {sum(norm_window)} but it should be '1'.\"\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:52:59.211509Z",
          "iopub.status.busy": "2020-10-07T14:52:59.210508Z",
          "iopub.status.idle": "2020-10-07T14:52:59.229497Z",
          "shell.execute_reply": "2020-10-07T14:52:59.228498Z",
          "shell.execute_reply.started": "2020-10-07T14:52:59.211509Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File close"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def file_close(files):\n",
        "    \"\"\"\n",
        "    Closes file(s) when 'with open() as file_object' is not used.\n",
        "\n",
        "    Parameter:\n",
        "        files (list (file object)): A list of file object(s) to be closed.\n",
        "    \"\"\"\n",
        "\n",
        "    n_files = len(files)\n",
        "\n",
        "    for file in files:  # Close each open file.\n",
        "        file.close()\n",
        "\n",
        "    if n_files > 1:\n",
        "        printmd(f\"**The {n_files} imported files are closed.**\", \"green\")\n",
        "\n",
        "    else:\n",
        "        printmd(f\"**The imported file is closed.**\", \"green\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:53:01.057964Z",
          "iopub.status.busy": "2020-10-07T14:53:01.057964Z",
          "iopub.status.idle": "2020-10-07T14:53:01.061962Z",
          "shell.execute_reply": "2020-10-07T14:53:01.061962Z",
          "shell.execute_reply.started": "2020-10-07T14:53:01.057964Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load .SPE files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class File:\n",
        "\n",
        "    \"\"\"\n",
        "    This class deals with importing only .SPE files and displaying the relevant information. The relevant data is shown for       each file while the metadata is only shown once; since, it's a standard experimental practice to keep most of the             parameters same for the same kind of experiment. It also raises appropriate errors or pass alert messages when               inconstistancy is found in data or metadata. The most of the parameters are extracted from the .SPE file header; however     some parameters such as experiment temp., pressure, incident power, and source wavelength are extracted from the file         name. Therefor, please use the prefered file naming convention for optimum results.\n",
        "\n",
        "    Use Defined Functions:\n",
        "        import_files(ftype, fextension, dialogue_title)\n",
        "        printmd(string, color)\n",
        "        read_at(file, position, size, dtype)\n",
        "\n",
        "    Methods:\n",
        "        _load_spe_files(self,)\n",
        "\n",
        "        _spe_read(self, file): Feed .spe file in a loop.\n",
        "\n",
        "            Paramers:\n",
        "                file (binary file object): Feed a binary file object using an \"open()\" function.\n",
        "\n",
        "            Methods:\n",
        "                # ---------- from file name ---------- #\n",
        "                _step_glue()\n",
        "                _experiment_temp()\n",
        "                _excitation_source()\n",
        "                _incident_power()\n",
        "\n",
        "                # ---------- from file ---------- #\n",
        "                _exposure_time()\n",
        "                _accumulations()\n",
        "                _data_dimension()\n",
        "                _no_frames()\n",
        "                _axes()\n",
        "                _experiment_data()\n",
        "                _pressure()\n",
        "                _grating()\n",
        "\n",
        "            Misc. variables:\n",
        "                self.wl_flag\n",
        "                self.fname_corr_flag\n",
        "\n",
        "            Returns:\n",
        "                spedict (dictonary): Contains information about the experimental conditions\n",
        "                     and data of a file extracted using the above methods.\n",
        "\n",
        "        _standard_info(self,)\n",
        "            Methods:\n",
        "                # ---------- from file ---------- #\n",
        "                _no_frames()\n",
        "                _detector_temp()\n",
        "                _intensified_gain()\n",
        "                _versions()\n",
        "                _data_corrections()\n",
        "                _messege()\n",
        "\n",
        "    Returns: Displays information about the experimental conditions which should be the constant for all the experiments.\n",
        "\n",
        "        NOTE: The methods can be called upon as class_obj.method().nested_method()\n",
        "    \"\"\"\n",
        "\n",
        "    ###################### Header offsets (gobally available within this class) (GLOBAL_CONSTANT_NAME) ######################\n",
        "    ACCUMULATIONS1 = 668  # When accumulations are < 32767\n",
        "    ACCUMULATIONS2 = 1422  # When accumulations are > 32767\n",
        "    BG_CORRECTION = 150  # 1 if background subtraction done\n",
        "    DATA_START = 4100\n",
        "    CONTROLLER_VERSION = 0\n",
        "    COSMIC_CORRECTION = 1438  # Flag\n",
        "    COSMIC_CORR_TYPE = 1440\n",
        "    COSMIC_THRESHOLD = 1442\n",
        "    DETECTOR_TEMP = 36\n",
        "    EXPOSURE_TIME = 10\n",
        "    EXPERIMENT_DATE = 20\n",
        "    EXPERIMENT_TIME_LOCAL = 172\n",
        "    #     FILE_COMMENTS = 200\n",
        "    FLATFIELD_CORRECTION = 706  # 1 if flat fiels is applied\n",
        "    #     GAIN = 198  # NO idea!\n",
        "    GRATING_GROOVES = 650\n",
        "    HEADER_VERSION = 1992\n",
        "    NUM_FRAMES = 1446\n",
        "    NUM_ROI = 1488  # or 1510; dtype = short Still not working.\n",
        "    PIMAX_GAIN = 148\n",
        "    READOUT_TIME = 672\n",
        "    SOFTWARE_PACKAGE = 1508  # Software package created this file\n",
        "    SOFTWARE_VERSION = 688  # Version of SW creating this file.\n",
        "    STEP_GLUE_FLAG = 76\n",
        "    #     WAVELENGTH_CENTER = 72  # Not working for Step&Glue mode\n",
        "    #     WAVELENGTH_END = 82  # Only working for Step&Glue mode\n",
        "    WAVELENGTH_OVERLAP = 86\n",
        "    #     WAVELENGTH_START = 78  # Only working for Step&Glue mode\n",
        "    WAVELENGTH_RESOLUTION = 90  # Only working for Step&Glue mode\n",
        "    X_PIXELS = 42\n",
        "    Y_PIXELS = 656\n",
        "\n",
        "    ###################### Start of X Calibration Structure (3000 - 3488) ######################\n",
        "    X_CALIBRATION_VALID = 3098  # flag if calibration is valid\n",
        "    X_LASER_POSITION = 3311\n",
        "    #     X_OFFSET = 3000  # offset for absolute data scaling\n",
        "    X_POLYNOMIAL_ORDER = 3101  # ORDER of calibration POLYNOM\n",
        "    X_POLYNOMIAL_COEFFICIENT = 3263  # polynom COEFFICIENTS\n",
        "\n",
        "    ###################### Start of Y Calibration Structure (3489 - 3977) ######################\n",
        "    Y_CALIBRATION_VALID = 3587  # flag if calibration is valid\n",
        "    #     Y_OFFSET = 3489  # offset for absolute data scaling\n",
        "    Y_POLYNOMIAL_ORDER = 3590  # ORDER of calibration POLYNOM\n",
        "    Y_POLYNOMIAL_COEFFICIENT = 3752  # polynom COEFFICIENTS\n",
        "\n",
        "    # -------------------------------------------------------------------------------------------------------------------#\n",
        "\n",
        "    # self (instance of a class) gives access to use the attributes and methods of the class. It binds the attributes with the given arguments.\n",
        "    def __init__(\n",
        "        self,\n",
        "    ):\n",
        "        \"\"\"__init__ method’s docstring is inaccurate — it just initializes the object to its factory-default settings after its creation.\"\"\"\n",
        "        self._load_spe_files()\n",
        "\n",
        "    # ----------------------------------------- Method to import only .SPE files! -----------------------------------------#\n",
        "    def _load_spe_files(\n",
        "        self,\n",
        "    ):\n",
        "\n",
        "        try:\n",
        "            self.fnames = import_files(\n",
        "                ftype=\".SPE files\",\n",
        "                fextension=\".*spe\",\n",
        "                dialogue_title=\"Import .SPE files\",\n",
        "            )\n",
        "\n",
        "        except IndexError:\n",
        "            raise LookupError(\"Please select at least one .SPE file to proceed!\")\n",
        "\n",
        "    # ---------------------------------------- Method to read imported .SPE file(s) ----------------------------------------#\n",
        "    def _spe_read(self, file):\n",
        "        \"\"\"\n",
        "        Reads the data, the header (other vital info.), and the file name from the imported .SPE file.\n",
        "        The extracted data is then assigned to a dictionary (spedict) and dipöayed as the dataframe.\n",
        "        \"\"\"\n",
        "\n",
        "        full_path = Path(file).resolve()\n",
        "\n",
        "        ####################### Flags #######################\n",
        "        self.wl_flag = 0\n",
        "        self.fname_corr_flag = 0\n",
        "        # ----------------------------------------------------\n",
        "\n",
        "        self.name = full_path.stem\n",
        "        # self.nameCorrect0 = self.name.replace(\"-\", \"_\")  # string.replace(old, new, count) iff old values is found!\n",
        "        self.nameCorrect0 = self.name\n",
        "        self.nameCorrect1 = self.nameCorrect0.replace(\n",
        "            \" \",\n",
        "            \"_\",\n",
        "        )\n",
        "        self.nameCorrect2 = self.nameCorrect1.lower()\n",
        "        self.nameCorrect3 = self.nameCorrect2.replace(\n",
        "            \"milibar\",\n",
        "            \"mbar\",\n",
        "        )\n",
        "        self.nameCorrect4 = self.nameCorrect3.replace(\n",
        "            \"mb\",\n",
        "            \"mbar\",\n",
        "        )\n",
        "        self.nameCorrect5 = self.nameCorrect4.replace(\n",
        "            \"µw\",\n",
        "            \"uw\",\n",
        "        )\n",
        "\n",
        "        self.name_split_list = self.nameCorrect1.split(\n",
        "            \"_\"\n",
        "        )  # Split chuncks using \"_\" delimiter.\n",
        "        self.name_split_list1 = self.nameCorrect5.split(\"_\")\n",
        "\n",
        "        # --------------- The following info is not stored in a .SPE header. It is extracted from a file name. ------------#\n",
        "        def _experiment_temp():\n",
        "            \"\"\"\n",
        "            Returns the temperature at which the experiment was performed.\n",
        "            The temperature value is extracted from the file name (if extractable!),\n",
        "            otherwise asks the user to  input it manually.\n",
        "            \"\"\"\n",
        "\n",
        "            if \"RT\" in self.nameCorrect1:\n",
        "                self.temperature = 293 * u.degK\n",
        "\n",
        "            elif \"K\" in self.nameCorrect1:\n",
        "                subString = \"K\"\n",
        "                result = [aa for aa in self.name_split_list if subString in aa]\n",
        "                self.temperature = int(result[0][0:-1]) * u.degK\n",
        "\n",
        "                if self.temperature == \"K\":\n",
        "                    temp = self.name_split_list.index(\"K\")\n",
        "                    self.temperature = (\n",
        "                        int(self.name_split_list[temp - 1]) * u.degK\n",
        "                    )  # + self.name_split_list[temp]\n",
        "\n",
        "                else:\n",
        "                    pass \n",
        "                  \n",
        "            else:\n",
        "                print(\"\\n\")\n",
        "                printmd(\n",
        "                    f\"Temp. info is either mising or could not be extracted from {self.name}.\",\n",
        "                    \"yellow\",\n",
        "                )\n",
        "                self.fname_corr_flag = 1\n",
        "\n",
        "                while True:\n",
        "                    try:\n",
        "                        self.temperature = (\n",
        "                            int(input(f\"Pls. enter temp. (e.g. xx): \")) * u.degK\n",
        "                        )\n",
        "\n",
        "                        if self.temperature < 0:\n",
        "                            raise ValueError\n",
        "                        else:\n",
        "                            pass\n",
        "\n",
        "                    except ValueError:\n",
        "                        printmd(\"Pls. enter a positive integer value only!\", \"red\")\n",
        "                        continue\n",
        "\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "            return self.temperature\n",
        "            self.fname_corr_flag = 1\n",
        "\n",
        "        def _excitation_source():\n",
        "            \"\"\"\n",
        "            Returns the excitation source wavelength used for the given experiment.\n",
        "            The wavelength is extracted from file name (if extractable!), otherwise asks the user to input it manually.\n",
        "            \"\"\"\n",
        "\n",
        "            if \"nm\" in self.nameCorrect1 and (\n",
        "                \"cw\" in self.nameCorrect5 or \"pulse\" in self.nameCorrect5\n",
        "            ):\n",
        "\n",
        "                if \"cw\" in self.nameCorrect5:\n",
        "                    subString = \"nm\"\n",
        "                    result = [aa for aa in self.name_split_list1 if subString in aa]\n",
        "                    self.ext_source = (\n",
        "                        int(result[0][0:-6]) * u.nm\n",
        "                    )  # strip nm(cw) (last 6 characacters)\n",
        "\n",
        "                    if result[0] == \"nm\":\n",
        "                        wvlngth = self.name_split_list.index(\"nm\")\n",
        "                        self.ext_source = int(self.name_split_list[wvlngth - 1]) * u.nm\n",
        "                        self.ext_source_string = f\"{self.ext_source} (CW)\"\n",
        "\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                    self.ext_source_string = f\"{self.ext_source} (CW)\"\n",
        "\n",
        "                elif \"pulse\" in self.nameCorrect5:\n",
        "                    subString = \"nm\"\n",
        "                    result = [aa for aa in self.name_split_list1 if subString in aa]\n",
        "                    self.ext_source = (\n",
        "                        int(result[0][0:-9]) * u.nm\n",
        "                    )  # strip nm(pulse) (last 9 characacters)\n",
        "\n",
        "                    if result[0] == \"nm\":\n",
        "                        wvlngth = self.name_split_list.index(\"nm\")\n",
        "                        self.ext_source = int(self.name_split_list[wvlngth - 1]) * u.nm\n",
        "                        self.ext_source_string = f\"{self.ext_source} (pulsed)\"\n",
        "\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                    self.ext_source_string = f\"{self.ext_source} (pulsed)\"\n",
        "\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "            elif (\n",
        "                \"wl\" in self.nameCorrect5\n",
        "                or \"refl\" in self.nameCorrect5\n",
        "                or \"rfl\" in self.nameCorrect5\n",
        "                or \"cnt\" in self.nameCorrect5\n",
        "            ):\n",
        "                self.ext_source_string = \"White light\"\n",
        "                self.wl_flag = 1\n",
        "\n",
        "            else:\n",
        "                print(\"\\n\")\n",
        "                printmd(\n",
        "                    f\"The excitation wavelength info is either mising or could not be extracted from {self.name}.\",\n",
        "                    \"yellow\",\n",
        "                )\n",
        "\n",
        "                while True:\n",
        "                    try:\n",
        "                        self.ext_source_string = input(\n",
        "                            \"Pls. enter excitation wavelength (e.g. xxx nm (CW/pulsed) or white light (wl)): \"\n",
        "                        )\n",
        "                        if (\n",
        "                            self.ext_source_string == \"wl\"\n",
        "                            or self.ext_source_string == \"white light\"\n",
        "                        ):\n",
        "                            self.ext_source_string = \"White light\"\n",
        "                            self.wl_flag = True\n",
        "                            break\n",
        "\n",
        "                        elif (\n",
        "                            \"CW\" in self.ext_source_string\n",
        "                            or \"cw\" in self.ext_source_string\n",
        "                        ):\n",
        "                            # Find numerical values from the string and store them in a list.\n",
        "                            self.ext_source = [\n",
        "                                int(aa)\n",
        "                                for aa in self.ext_source_string.split()\n",
        "                                if aa.isdigit()\n",
        "                            ]\n",
        "                            self.ext_source = self.ext_source[0] * u.nm\n",
        "                            self.ext_source_string = f\"{self.ext_source} (CW)\"\n",
        "                            break\n",
        "\n",
        "                        elif \"pulse\" in self.ext_source_string:\n",
        "                            # Find numerical values from the string and store them in a list.\n",
        "                            self.ext_source = [\n",
        "                                int(aa)\n",
        "                                for aa in self.ext_source_string.split()\n",
        "                                if aa.isdigit()\n",
        "                            ]\n",
        "                            self.ext_source = self.ext_source[0] * u.nm\n",
        "                            self.ext_source_string = f\"{self.ext_source} (pulsed)\"\n",
        "                            break\n",
        "\n",
        "                        else:\n",
        "                            raise ValueError  # If a value is missing then raise the value error.\n",
        "\n",
        "                    except ValueError:\n",
        "                        printmd(\"CW or pulsed was missing!\", \"red\")\n",
        "                        continue\n",
        "\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "            return self.ext_source_string\n",
        "            self.fname_corr_flag = 1\n",
        "\n",
        "        def _incident_power():\n",
        "            \"\"\"\n",
        "            Returns the incident power used for the given experiment. The incident power is extracted from the file name (if             extractable!), otherwise asks the user to  input it manually. It is prefered to measure the incident power right             before the sample.\n",
        "\n",
        "            NOTE: Generally, for CW laser source the incident power reading is correct with normal diode based power meters.\n",
        "            However, for pulsed lasers, one should use the pulsed power meter to get the 'rms'/'aveage' power with pick                   power. Usually in the data analysis the power density ([incident power]/[laser spot area]) is a useful quantity               rather than just the incident power.\n",
        "            \"\"\"\n",
        "\n",
        "            if \"uw\" in self.nameCorrect5:\n",
        "                subString = \"uw\"\n",
        "                result = [aa for aa in self.name_split_list1 if subString in aa]\n",
        "                self.power = float(result[0][0:-2]) * u.microwatt\n",
        "\n",
        "                if result[0] == \"uw\":\n",
        "                    power_index = self.name_split_list1.index(\"uw\")\n",
        "                    self.power = (\n",
        "                        float(self.name_split_list1[power_index - 1]) * u.microwatt\n",
        "                    )\n",
        "\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "            elif \"mw\" in self.nameCorrect2:\n",
        "                subString = \"mw\"\n",
        "                result = [aa for aa in self.name_split_list1 if subString in aa]\n",
        "                self.power = float(result[0][0:-2]) * u.milliwatt\n",
        "\n",
        "                if result[0] == \"mw\":\n",
        "                    power_index = self.name_split_list1.index(\"mw\")\n",
        "                    self.power = (\n",
        "                        float(self.name_split_list1[power_index - 1]) * u.milliwatt\n",
        "                    )\n",
        "\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "            elif self.wl_flag == 1:\n",
        "                self.power = \"na\"\n",
        "\n",
        "            else:\n",
        "                print(\"\\n\")\n",
        "                printmd(\n",
        "                    f\"Incident power info is either mising or could not be extracted from {self.name}.\",\n",
        "                    \"yellow\",\n",
        "                )\n",
        "\n",
        "                while True:\n",
        "                    try:\n",
        "                        power_string = input(\n",
        "                            \"Pls. enter incident power (e.g. xxx u(m)wW:\"\n",
        "                        )\n",
        "\n",
        "                        if \"uW\" in power_string:\n",
        "                            self.power = [\n",
        "                                float(aa) for aa in power_string.split() if aa.isdigit()\n",
        "                            ]\n",
        "                            self.power = self.power[0] * u.microwatt\n",
        "                            break\n",
        "\n",
        "                        elif \"mW\" in power_string:\n",
        "                            self.power = [\n",
        "                                float(aa) for aa in power_string.split() if aa.isdigit()\n",
        "                            ]\n",
        "                            self.power = self.power[0] * u.milliwatt\n",
        "                            break\n",
        "\n",
        "                        elif \"na\" in power_string:\n",
        "                            self.power = power_string\n",
        "\n",
        "                        else:\n",
        "                            raise ValueError\n",
        "\n",
        "                    except ValueError:\n",
        "                        printmd(\" Unit (u/mW) was missing!\", \"red\")\n",
        "                        continue\n",
        "\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "            return self.power\n",
        "            self.fname_corr_flag = 1\n",
        "\n",
        "        def _pressure():\n",
        "            \"\"\"\n",
        "            Returns the sample pressure condition for the given experiment.\n",
        "            The pressure is extracted from the file name (if extractable!),\n",
        "            otherwise asks the user to  input it manually. \\n\n",
        "            \"\"\"\n",
        "\n",
        "            if \"mbar\" in self.nameCorrect5:\n",
        "                subString = \"mbar\"\n",
        "                result = [aa for aa in self.name_split_list1 if subString in aa]\n",
        "                self.pressure = float(result[0][0:-6]) * u.millibar\n",
        "\n",
        "                if result[0] == \"mbar\":\n",
        "                    pressure_index = self.name_split_list1.index(\"mbar\")\n",
        "                    self.pressure = (\n",
        "                        float(self.name_split_list1[power_index - 1]) * u.millibar\n",
        "                    )\n",
        "\n",
        "                else:\n",
        "                    pass\n",
        "\n",
        "            elif \"atm\" in self.nameCorrect5:\n",
        "                self.pressure = 1.013e3 * u.mbar\n",
        "\n",
        "            else:\n",
        "                print(\"\\n\")\n",
        "                printmd(\n",
        "                    f\"The pressure info is either mising or could not be extracted {self.name}.\",\n",
        "                    \"yellow\",\n",
        "                )\n",
        "\n",
        "                while True:\n",
        "                    try:\n",
        "                        pressure_string = input(\n",
        "                            \"Pls. enter pressure (e.g. x.xE(-)x mbar):\"\n",
        "                        )\n",
        "\n",
        "                        if \"mbar\" in pressure_string:\n",
        "                            self.pressure = [\n",
        "                                float(aa)\n",
        "                                for aa in pressure_string.split()\n",
        "                                if aa.isdigit()\n",
        "                            ]\n",
        "                            self.pressure = self.pressure[0] * u.mbar\n",
        "                            break\n",
        "\n",
        "                        elif \"na\" in pressure_string:\n",
        "                            self.pressure = pressure_string\n",
        "\n",
        "                        else:\n",
        "                            raise ValueError\n",
        "\n",
        "                    except ValueError:\n",
        "                        printmd(\" Unit (mbar) was missing!\", \"red\")\n",
        "                        continue\n",
        "\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "            return self.pressure\n",
        "            self.fname_corr_flag = 1\n",
        "\n",
        "        # ----------------------------------------------------------------------------------------------------------------- #\n",
        "\n",
        "        \"\"\"\n",
        "            with open(file, mode=\"rb\") as self.spe: # The \"with open()\" method ensures the closing of file at the end after               reading the respective .SPE binary (rb: read binary) files. This is a better way to work with the files,                     restricting writing to a file outside the \"with\" method. Nevertheless, I had to use the below method so that the             \"standard_info\" function can read the file and display the informarion only once. Otherwise, it will display the             standard experimental settings for each file.\n",
        "        \"\"\"\n",
        "\n",
        "        # Open files with \"read binary\" mode and return a corresponding file object. 'file' is a path-like object (string) giving the pathname.\n",
        "        self.spe = open(file, mode=\"rb\") \n",
        "\n",
        "        def _data_dimension():\n",
        "            \"\"\"\n",
        "            Returns the dimensions of X and Y axis pixels.\n",
        "\n",
        "            REMARK: The manual is misleading for datatypes. It says short(int8) datatype but actually needs int16.\n",
        "            I had to convert the dimensions into int64 type, otherwise it does not work when I want to exctract the actulal               data bytes using x_Dim*y_Dim in the \"_experiment_data()\" method.\n",
        "            \"\"\"\n",
        "\n",
        "            self.x_Dim = np.int64(\n",
        "                read_at(\n",
        "                    self.spe,\n",
        "                    self.X_PIXELS,\n",
        "                    1,\n",
        "                    np.int16,\n",
        "                )[0]\n",
        "            )  # no. of pixels on x axis\n",
        "            self.y_Dim = np.int64(\n",
        "                read_at(\n",
        "                    self.spe,\n",
        "                    self.Y_PIXELS,\n",
        "                    1,\n",
        "                    np.int16,\n",
        "                )[0]\n",
        "            )  # no. of pixels on y axis\n",
        "\n",
        "            return self.y_Dim, self.x_Dim\n",
        "\n",
        "        def _exposure_time():\n",
        "            self.seconds = read_at(\n",
        "                self.spe,\n",
        "                self.EXPOSURE_TIME,\n",
        "                1,\n",
        "                np.float32,\n",
        "            )[0]\n",
        "\n",
        "            return self.seconds\n",
        "\n",
        "        def _accumulations():  # The data type should be different for both the cases. Nonetheless,an experiment with >32767 accumulation is needed to check the code.\n",
        "            self.accumulations = read_at(\n",
        "                self.spe,\n",
        "                self.ACCUMULATIONS1,\n",
        "                1,\n",
        "                np.int16,\n",
        "            )[0]\n",
        "            if self.accumulations == -1:  # if > 32767\n",
        "                self.accumulations = read_at(\n",
        "                    self.spe,\n",
        "                    self.ACCUMULATIONS2,\n",
        "                    1,\n",
        "                    np.int16,\n",
        "                )[0]\n",
        "\n",
        "            return self.accumulations\n",
        "\n",
        "        # No idea what does it represent?\n",
        "        def _no_frames():  # Number of image frames in the SPE file\n",
        "            self.frames = read_at(\n",
        "                self.spe,\n",
        "                self.NUM_FRAMES,\n",
        "                1,\n",
        "                np.int16,\n",
        "            )[0]\n",
        "\n",
        "            return self.frames\n",
        "\n",
        "        def _step_glue():\n",
        "            self.step_Glue = read_at(\n",
        "                self.spe,\n",
        "                self.STEP_GLUE_FLAG,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            self.sgString = \"No\"\n",
        "\n",
        "            if self.step_Glue == 1:\n",
        "                self.sgString = \"Yes\"\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            return self.sgString\n",
        "\n",
        "        def _axes():\n",
        "            \"\"\"\n",
        "            Axis calibration with a polynomial function of the order of 1 (for Step&Glue) and 2 (for non SG);\n",
        "            meaning the non-SG x-axis is calibrated with a quadratic equation (coff1.x^2 + coff2.x^1 + coff2.x^0),\n",
        "            while the SG x-axis is claibrated with a linear eq.\n",
        "            \"\"\"\n",
        "            # ------------------------------------------ x-axis calibration -------------------------------------------#\n",
        "\n",
        "            # It always shows 532 nm. Perhaps the 532 nm laser was used for x-calibration. during installation of the CCD.\n",
        "            self.laser = read_at(\n",
        "                self.spe,\n",
        "                self.X_LASER_POSITION,\n",
        "                1,\n",
        "                np.double,\n",
        "            )[0]\n",
        "            # self.ROI = self.read_at(self.spe, self.NUM_ROI, 10, np.int8)[0]  # No. of ROIs; NOT WORKING!\n",
        "\n",
        "            xPolyOrder = read_at(\n",
        "                self.spe,\n",
        "                self.X_POLYNOMIAL_ORDER,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            # No. of total coeff=6; no. of non-zero coeff.= polyOrder+1\n",
        "            xPolyCoeff = np.float32(\n",
        "                read_at(\n",
        "                    self.spe,\n",
        "                    self.X_POLYNOMIAL_COEFFICIENT,\n",
        "                    6,\n",
        "                    np.double,\n",
        "                )\n",
        "            )\n",
        "            # print(\"X Polynomial coeff:\", xPolyCoeff)\n",
        "            xCalibValid = read_at(\n",
        "                self.spe,\n",
        "                self.X_CALIBRATION_VALID,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "\n",
        "            if xCalibValid:  # Slice only non-zero array elements.\n",
        "                xCoeff = xPolyCoeff[: xPolyOrder + 1]  \n",
        "                # reverse coefficients to use numpy polyval; <object_name>[<start_index>, <stop_index>, <step>]\n",
        "                xCoeffRvrs = np.array(xCoeff[::-1])\n",
        "                # 1d array of a pixel range; from 1 (to usually 1100)\n",
        "                xPixels = np.linspace(1, self.x_Dim, self.x_Dim)  \n",
        "                # If p is of length N, then function returns: p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]\n",
        "                # x_axis = np.polyval(xCoeffRvrs, xPixels,)\n",
        "                # The 1d (or 0d) ndarrays can be a problem. There are many ways of adding a 2nd dimension like,\"[None,:]                       syntax, reshape  ndmin=2, np.atleast_2d, np.expand_dims\".\n",
        "                # Store in a 2D array (matrix) with a shape of (n_rows (i.e. 1), n_cols (i.e. xPixels)).\n",
        "                # This way it's more convinient to think and also for further analysis (e.g. for reversing data points.)\n",
        "                # self.x_Axis = np.reshape(x_axis, (1, np.shape(x_axis)[0]))\n",
        "                self.x_Axis = np.array(\n",
        "                    np.polyval(\n",
        "                        xCoeffRvrs,\n",
        "                        xPixels,\n",
        "                    ),\n",
        "                    ndmin=2,\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                self.x_Axis = np.array(\n",
        "                    np.linspace(start=1, stop=self.x_Dim, counts=self.x_Dim), ndmin=2\n",
        "                )\n",
        "\n",
        "            # Selecting first and last elements of the 1D X-axis matrix or a 2D array.\n",
        "            self.xaxis_range = [self.x_Axis[0][0], self.x_Axis[0][-1]]\n",
        "\n",
        "            if self.step_Glue == 1:\n",
        "                self.resolution = read_at(\n",
        "                    self.spe,\n",
        "                    self.WAVELENGTH_RESOLUTION,\n",
        "                    1,\n",
        "                    np.float32,\n",
        "                )[0]\n",
        "                self.overlap = read_at(\n",
        "                    self.spe,\n",
        "                    self.WAVELENGTH_OVERLAP,\n",
        "                    1,\n",
        "                    np.float32,\n",
        "                )[0]\n",
        "\n",
        "            else:\n",
        "                self.resolution = self.x_Axis[0][1] - self.x_Axis[0][0]\n",
        "                self.overlap = \"None\"\n",
        "\n",
        "            # -------------------------------------------- y-axis calibration ---------------------------------------------#\n",
        "            yPolyOrder = read_at(\n",
        "                self.spe,\n",
        "                self.Y_POLYNOMIAL_ORDER,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            yPolyCoeff = np.float32(\n",
        "                read_at(\n",
        "                    self.spe,\n",
        "                    self.Y_POLYNOMIAL_COEFFICIENT,\n",
        "                    6,\n",
        "                    np.double,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            yCalibValid = read_at(\n",
        "                self.spe,\n",
        "                self.Y_CALIBRATION_VALID,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "\n",
        "            if yCalibValid:\n",
        "                yCoeff = yPolyCoeff[: yPolyOrder + 1]\n",
        "                yCoeffRvrs = np.array(\n",
        "                    yCoeff[::-1]\n",
        "                )  # reverse coefficients to use numpy polyval\n",
        "                yPixels = np.linspace(1, self.y_Dim, self.y_Dim)\n",
        "                self.y_Axis = np.array(\n",
        "                    np.polyval(\n",
        "                        yCoeffRvrs,\n",
        "                        yPixels,\n",
        "                    ),\n",
        "                    ndmin=2,\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                self.y_Axis = np.array(np.linspace(1, self.y_Dim, self.y_Dim), ndmin=2)\n",
        "\n",
        "            if len(self.y_Axis) > 1:\n",
        "                self.yaxis_range = [\n",
        "                    self.y_Axis[0],\n",
        "                    self.y_Axis[-1],\n",
        "                ]\n",
        "\n",
        "            else:\n",
        "                self.yaxis_range = \"N.A. (Binned)\"\n",
        "\n",
        "            return (\n",
        "                self.x_Axis,\n",
        "                self.xaxis_range,\n",
        "                self.y_Axis,\n",
        "                self.yaxis_range,\n",
        "                self.resolution,\n",
        "                self.overlap,\n",
        "            )\n",
        "\n",
        "        def _experiment_data():\n",
        "            \"\"\"Reads data (with correct data conversion type for different scenarios) from an imported .SPE file from all                    .SPE files and reshapes it into the [[no. of frames]*[x axis dim.]*[y axis dim.]] format. If any anomalies                    happen while reading the data such as occuring of any \"0\" then raises an exception.\n",
        "\n",
        "            NOTE: If there are more no. of frames (>1) then the code needs to be modified.\"\"\"\n",
        "\n",
        "            dataArray = []\n",
        "\n",
        "            for frame in range(self.frames):\n",
        "                # The final extracted data should be of float type otherwise performing operations on data would be cumbersome.\n",
        "                # Special care is required when the data is converted using the given datataype!\n",
        "                # When SG is used, the overlapping data is of float type in the original .SPE files.\n",
        "                if self.step_Glue == 1:\n",
        "                    rawData = read_at(\n",
        "                        self.spe, self.DATA_START, self.x_Dim * self.y_Dim, np.float32\n",
        "                    )\n",
        "\n",
        "                # This will work only when the data value is <32767.\n",
        "                else:\n",
        "                    rawData = np.array(\n",
        "                        read_at(\n",
        "                            self.spe,\n",
        "                            self.DATA_START,\n",
        "                            self.x_Dim * self.y_Dim,\n",
        "                            np.uint16,\n",
        "                        ),\n",
        "                        dtype=np.float32,\n",
        "                    )\n",
        "\n",
        "                    # uint32 is only required when atleast one data value is >32767. Do not use it otherwise.\n",
        "                    if (\n",
        "                        rawData[1] == 0\n",
        "                    ):  # One special case is solved. May be there are more!\n",
        "                        rawData = np.array(\n",
        "                            read_at(\n",
        "                                self.spe,\n",
        "                                self.DATA_START,\n",
        "                                self.x_Dim * self.y_Dim,\n",
        "                                np.uint32,\n",
        "                            ),\n",
        "                            dtype=np.float32,\n",
        "                        )\n",
        "\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                dataArray.append(rawData)\n",
        "\n",
        "            self.data = np.asanyarray(dataArray).reshape(\n",
        "                self.frames,\n",
        "                self.y_Dim,\n",
        "                self.x_Dim,\n",
        "            )\n",
        "\n",
        "            if self.data.any() == 0:\n",
        "                raise Exception(\n",
        "                    \"Data value 0 found! Either the {} file is corrupted or something went wrong with the data extraction. Please check the datatype to read binary data correctly.\".format(\n",
        "                        self.name\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            return self.data\n",
        "\n",
        "        def _grating():\n",
        "            self.grooves = read_at(\n",
        "                self.spe,\n",
        "                self.GRATING_GROOVES,\n",
        "                1,\n",
        "                np.float32,\n",
        "            )[0]\n",
        "            if self.grooves != 300:\n",
        "                printmd(\n",
        "                    f\"The {self.name} experiment was performed with {self.grooves}/mm grating.\"\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "            return self.grooves\n",
        "\n",
        "        _step_glue()\n",
        "        _no_frames()\n",
        "        _experiment_temp()\n",
        "        _excitation_source()\n",
        "        _incident_power()\n",
        "        _exposure_time()\n",
        "        _accumulations()\n",
        "        _data_dimension()\n",
        "        _axes()\n",
        "        _experiment_data()\n",
        "        _pressure()\n",
        "        _grating()\n",
        "\n",
        "        spedict = {\n",
        "            \"Name\": self.name,\n",
        "            \"01) Data\": self.data,\n",
        "            \"02) Wavelength range [nm]\": [\n",
        "                round(\n",
        "                    self.xaxis_range[0],\n",
        "                    2,\n",
        "                ),\n",
        "                round(\n",
        "                    self.xaxis_range[1],\n",
        "                    2,\n",
        "                ),\n",
        "            ],\n",
        "            \"03) Temperature\": self.temperature,\n",
        "            \"04) Incident power\": self.power,\n",
        "            \"05) Exposure [sec]\": self.seconds,\n",
        "            \"06) Accumulation(s)\": self.accumulations,\n",
        "            \"07) Excitation source\": self.ext_source_string,\n",
        "            #             \"08) Strip [px]\": self.yaxis_range,\n",
        "            \"08) Dimension [px]\": (\n",
        "                self.y_Dim,\n",
        "                self.x_Dim,\n",
        "            ),\n",
        "            \"09) Resolution [nm]\": self.resolution,\n",
        "            # \"10) No. of ROIs\": self.ROI,\n",
        "            \"10) Overlap [nm]\": self.overlap,\n",
        "            \"11) Pressure\": self.pressure,\n",
        "            \"12) Grating [grooves/mm]\": self.grooves,\n",
        "        }\n",
        "\n",
        "        return spedict\n",
        "\n",
        "    # --------------------------------------------- Standard Information ---------------------------------------------------#\n",
        "    #  Needs to be printed only once since all the experiments were performed under the same conditions.\n",
        "    def _standard_info(self):\n",
        "        print(\"\\n\")\n",
        "        display(MD(\"**Standard information**\"))\n",
        "\n",
        "        def _messege():\n",
        "            if self.fname_corr_flag == 1:\n",
        "                print(\"\\n\")\n",
        "                messeges = {\n",
        "                    \"m0\": \"**Prefered name : sample_experiment_(img)_acc*expo(s)_source(cw/pulsed/wl)_power_temp_pressure \\nE.g. : WSe2/WS2_PL_2Dimg_10x120s_532nm(cw)_675µW_10K_5.2E-5mb**\"\n",
        "                }\n",
        "\n",
        "                printmd(messeges[\"m0\"], \"green\")\n",
        "\n",
        "        # No idea what does it represent?\n",
        "        def _no_frames():  # Number of image frames in the SPE file\n",
        "            frames = read_at(\n",
        "                self.spe,\n",
        "                self.NUM_FRAMES,\n",
        "                1,\n",
        "                np.int16,\n",
        "            )[0]\n",
        "            printmd(f\"No. of frames : {frames}\", \"white\")\n",
        "\n",
        "        def _experiment_date_time():\n",
        "            rawdate = read_at(\n",
        "                self.spe,\n",
        "                self.EXPERIMENT_DATE,\n",
        "                10,\n",
        "                np.int8,\n",
        "            )\n",
        "            dateString = \"\"\n",
        "            aa = 0\n",
        "            for ch in rawdate:\n",
        "                dateString += chr(ch)\n",
        "                aa += 1\n",
        "                if aa % 2 == 0 and aa < 4:\n",
        "                    dateString += \"-\"  # To make it more readable\n",
        "                elif aa == 5:\n",
        "                    dateString += \"-\"\n",
        "                else:\n",
        "                    pass\n",
        "            date = dateString\n",
        "\n",
        "            rawtime = read_at(\n",
        "                self.spe,\n",
        "                self.EXPERIMENT_TIME_LOCAL,\n",
        "                6,\n",
        "                np.int8,\n",
        "            )\n",
        "            timeString = \"\"\n",
        "            bb = 0\n",
        "            for ch in rawtime:\n",
        "                timeString += chr(ch)\n",
        "                bb += 1\n",
        "\n",
        "                if bb % 2 == 0 and bb < 5:\n",
        "                    timeString += \":\"  # To make it more readable\n",
        "            time = timeString\n",
        "\n",
        "        #             display(MD(\"Date and Time: {}, {}\".format(date, time)))\n",
        "\n",
        "        def _detector_temp():\n",
        "            temperature = read_at(\n",
        "                self.spe,\n",
        "                self.DETECTOR_TEMP,\n",
        "                1,\n",
        "                np.float32,\n",
        "            )[0]\n",
        "            if temperature > -120:\n",
        "                printmd(\n",
        "                    f\"The {self.spe} experiment was recorded at {temperature} °C chip temp. However, the chip temp. should be max. -120 °C. to improve the SNR for Priceton acton SPE2300 detector.\"\n",
        "                )\n",
        "\n",
        "            else:\n",
        "                printmd(f\"Detector temp. : {temperature} °C\")\n",
        "\n",
        "        def _intensified_gain():\n",
        "            iGain = read_at(\n",
        "                self.spe,\n",
        "                self.PIMAX_GAIN,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            printmd(f\"Intensified gain : {iGain}\")\n",
        "\n",
        "        def _versions():\n",
        "            package = read_at(\n",
        "                self.spe,\n",
        "                self.SOFTWARE_PACKAGE,\n",
        "                1,\n",
        "                np.uint8,\n",
        "            )[0]\n",
        "            controller = read_at(\n",
        "                self.spe,\n",
        "                self.CONTROLLER_VERSION,\n",
        "                16,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            header = read_at(\n",
        "                self.spe,\n",
        "                self.HEADER_VERSION,\n",
        "                1,\n",
        "                np.float32,\n",
        "            )[0]\n",
        "            software = read_at(\n",
        "                self.spe,\n",
        "                self.SOFTWARE_VERSION,\n",
        "                16,\n",
        "                np.int8,\n",
        "            )\n",
        "            softwareString = \"\"\n",
        "\n",
        "            for ch in software:\n",
        "                softwareString += chr(ch)\n",
        "\n",
        "            display(MD(\"**Version information :**\"))\n",
        "            printmd(f\"Software package : {package}\")\n",
        "            printmd(f\"Controller : {controller}\")\n",
        "            printmd(f\"Header : {header}\".format())\n",
        "            printmd(f\"Software : {softwareString}\")\n",
        "\n",
        "        def _data_corrections():\n",
        "            display(MD(\"**Data correction:**\"))\n",
        "            background = read_at(\n",
        "                self.spe,\n",
        "                self.BG_CORRECTION,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            bgString = \"No\"\n",
        "            if background == 1:\n",
        "                bgString = \"Yes\"\n",
        "            printmd(f\"Backgroung applied : {bgString}\")\n",
        "\n",
        "            flatField = read_at(\n",
        "                self.spe,\n",
        "                self.FLATFIELD_CORRECTION,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            ffString = \"No\"\n",
        "            if flatField == 1:\n",
        "                ffString = \"Yes\"\n",
        "            printmd(f\"Flat field applied : {ffString}\")\n",
        "\n",
        "            cosmic = read_at(\n",
        "                self.spe,\n",
        "                self.COSMIC_CORRECTION,\n",
        "                1,\n",
        "                np.int8,\n",
        "            )[0]\n",
        "            cosmicString = \"No\"\n",
        "            if cosmic == 1:\n",
        "                cosmicString = \"Yes\"\n",
        "\n",
        "            printmd(f\"Cosmic applied : {cosmicString}\")\n",
        "\n",
        "            if cosmic == 1:\n",
        "                cosmicCorrType = read_at(\n",
        "                    self.spe,\n",
        "                    self.COSMIC_CORR_TYPE,\n",
        "                    1,\n",
        "                    np.int8,\n",
        "                )\n",
        "                cosmicThreshold = read_at(\n",
        "                    self.spe,\n",
        "                    self.COSMIC_THRESHOLD,\n",
        "                    1,\n",
        "                    np.int8,\n",
        "                )\n",
        "                printmd(f\"Cosmic type : {cosmicCorrType}\")\n",
        "                printmd(f\"Cosmic threshold : {cosmicThreshold}\")\n",
        "\n",
        "        #             self.xGain = self.read_at(self.spe, GAIN, 1, np.int8)[0]\n",
        "\n",
        "        #             comments = self.read_at(self.spe, FILE_COMMENTS, 400, np.int8)\n",
        "        #             commentString=\"\"\n",
        "        #             for ch in comments:\n",
        "        #                 commentString += chr(ch)\n",
        "        #             print(\"Comments:\", commentString)\n",
        "\n",
        "        _no_frames()\n",
        "        _detector_temp()\n",
        "        _intensified_gain()\n",
        "        _versions()\n",
        "        _data_corrections()\n",
        "        _messege()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:13.346171Z",
          "iopub.status.busy": "2020-10-07T14:40:13.346171Z",
          "iopub.status.idle": "2020-10-07T14:40:13.417130Z",
          "shell.execute_reply": "2020-10-07T14:40:13.417130Z",
          "shell.execute_reply.started": "2020-10-07T14:40:13.346171Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflection contrast analysis"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fId = File()\n",
        "fileInfo = DF()  # Create a Dataframe\n",
        "\n",
        "spe_files = []\n",
        "data_All = []\n",
        "xaxis_All = []\n",
        "yaxis_All = []\n",
        "\n",
        "for files in fId.fnames:\n",
        "    # Append the output of spe_read() (spedict) into a dataframe.\n",
        "    fileInfo = fileInfo.append(\n",
        "        fId._spe_read(files),\n",
        "        ignore_index=True,\n",
        "    )\n",
        "    data_All.append(fId.data)\n",
        "    xaxis_All.append(fId.x_Axis)\n",
        "    yaxis_All.append(fId.y_Axis)\n",
        "    spe_files.append(fId.spe)  # Append file objects to close them later on!\n",
        "\n",
        "\n",
        "# The Pandas frame append function looses the order of dictionary columns and sorts them alphabatically. No idea how to fix it!\n",
        "# Display the file info in a tabular dataframe after transposing it.\n",
        "display(fileInfo.set_index(\"Name\").T)  \n",
        "\n",
        "fId._standard_info()  # call the function to present the standard info.\n",
        "\n",
        "\n",
        "file_close(spe_files)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:15.066001Z",
          "iopub.status.busy": "2020-10-07T14:40:15.065001Z",
          "iopub.status.idle": "2020-10-07T14:40:17.790103Z",
          "shell.execute_reply": "2020-10-07T14:40:17.790103Z",
          "shell.execute_reply.started": "2020-10-07T14:40:15.066001Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Axis and Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# u.enable_contexts('sp')\n",
        "\n",
        "# ------------------------------------------------------ X - axis ------------------------------------------------------#\n",
        "wavelength = Q_(xaxis_All, \"nm\")  # equvalent to xaxis_All * u.nm\n",
        "\n",
        "# print(wavelength.units)\n",
        "# print(wavelength.magnitude)\n",
        "\n",
        "\n",
        "with u.context(\"sp\"):\n",
        "    energy = wavelength.to(\"eV\")\n",
        "\n",
        "\"\"\"\n",
        "    If the X-axis is wavelength then there is no need to reverse the data.\n",
        "    When it's converted into the energy axis then it makes more sense to start the axis with ascending values\n",
        "\"\"\"\n",
        "\n",
        "energy = data_reverse(data=energy.magnitude)  # np array with a unit cannot be flipped.\n",
        "energy = np.round(energy, 5)\n",
        "energy = Q_(energy, \"eV\")  # reassign the unit.\n",
        "# print(energy.units)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------- Data -------------------------------------------------------- #\n",
        "data_All = data_reverse(data=data_All)\n",
        "rfl_sam = data_All[0][0]  # Select the data only\n",
        "rfl_sub = data_All[1][0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:19.473836Z",
          "iopub.status.busy": "2020-10-07T14:40:19.473836Z",
          "iopub.status.idle": "2020-10-07T14:40:19.483832Z",
          "shell.execute_reply": "2020-10-07T14:40:19.483832Z",
          "shell.execute_reply.started": "2020-10-07T14:40:19.473836Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Region selection"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "no_regns = 2\n",
        "stpts = [40, 21]\n",
        "endpts = [49, 34]\n",
        "\n",
        "printmd(\"**Reflection_sample info**\")\n",
        "rfl_sam_region, rfl_sam_region_binned = region_bin(\n",
        "    data=rfl_sam, no_regns=no_regns, stpts=stpts, endpts=endpts\n",
        ")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "printmd(\"**Reflection_substrate info**\")\n",
        "rfl_sub_region, rfl_sub_region_binned = region_bin(\n",
        "    data=rfl_sub, no_regns=no_regns, stpts=stpts, endpts=endpts\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:22.514118Z",
          "iopub.status.busy": "2020-10-07T14:40:22.513119Z",
          "iopub.status.idle": "2020-10-07T14:40:22.542101Z",
          "shell.execute_reply": "2020-10-07T14:40:22.541102Z",
          "shell.execute_reply.started": "2020-10-07T14:40:22.514118Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reflection contrast of selected (binned) regions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "printmd(\"**RC of selected regions**\")\n",
        "rflcnt_regn = reflection_contrast(rfl_sam_region, rfl_sub_region)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "printmd(\"**RC of binned selected regions**\")\n",
        "rflcnt_regn_binned = reflection_contrast(rfl_sam_region_binned, rfl_sub_region_binned)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:40:25.354911Z",
          "iopub.status.busy": "2020-10-07T14:40:25.353911Z",
          "iopub.status.idle": "2020-10-07T14:40:25.372900Z",
          "shell.execute_reply": "2020-10-07T14:40:25.372900Z",
          "shell.execute_reply.started": "2020-10-07T14:40:25.354911Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Differential reflection contrast"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rflcnt_regn_derv = differentiation(rflcnt_regn, energy)\n",
        "rflcnt_regn_derv_unit = rflcnt_regn_derv[0].units  # list object has no unit.\n",
        "print(\"\\n\")\n",
        "\n",
        "rflcnt_regn_binned_derv = differentiation(rflcnt_regn_binned, energy)\n",
        "rflcnt_regn_binned_derv_unit = rflcnt_regn_binned_derv[\n",
        "    0\n",
        "].units  # list object has no unit.\n",
        "print(rflcnt_regn_binned_derv_unit)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:53:13.707579Z",
          "iopub.status.busy": "2020-10-07T14:53:13.707579Z",
          "iopub.status.idle": "2020-10-07T14:53:13.721570Z",
          "shell.execute_reply": "2020-10-07T14:53:13.721570Z",
          "shell.execute_reply.started": "2020-10-07T14:53:13.707579Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving window filter"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 5\n",
        "\n",
        "rflcnt_regn_derv_flatMvgAvg = mvg_window_fltr(\n",
        "    data=rflcnt_regn_derv[0].magnitude, window_type=(\"flat\", 5), mode=\"reflect\"\n",
        ")\n",
        "# rflcnt_regn_derv_flatMvgAvg = mvg_window_fltr(data = data, window_type = ('flat', 5), mode='reflect')\n",
        "# window = signal.boxcar(51)\n",
        "print(rflcnt_regn_derv_flatMvgAvg)\n",
        "# print(window, len(window))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-07T14:54:03.501801Z",
          "iopub.status.busy": "2020-10-07T14:54:03.501801Z",
          "iopub.status.idle": "2020-10-07T14:54:03.514794Z",
          "shell.execute_reply": "2020-10-07T14:54:03.514794Z",
          "shell.execute_reply.started": "2020-10-07T14:54:03.501801Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Interactive) matplotlib ploting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "from cycler import cycler\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec as gridspec\n",
        "from matplotlib import (\n",
        "    image as mpimg,  # to dispay images (limited formats are supported)\n",
        ")\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rc, ticker\n",
        "from matplotlib.pyplot import imshow as imshow\n",
        "from matplotlib.ticker import (  # for labels formattings\n",
        "    FormatStrFormatter,\n",
        "    MultipleLocator,\n",
        ")\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "%matplotlib widget\n",
        "#%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global style setting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def _plot_params():\n",
        "\n",
        "    # ---------------------------- Font ---------------------------- #\n",
        "    # plt.rcParams['font.family'] = \"serif\" # by default Halvatic font is used\n",
        "    # plt.rcParams['font.serif'] = \"Helvetica\"\n",
        "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
        "    plt.rcParams[\"font.weight\"] = 200\n",
        "    plt.rcParams[\"text.usetex\"] = True  # use latex for all text handling.\n",
        "    plt.rcParams[\"axes.prop_cycle\"] = cycler(color=\"bgrcmyk\")\n",
        "    plt.rcParams[\"font.size\"] = 12\n",
        "\n",
        "    # ---------------------------- Figure ----------------------------#\n",
        "    plt.rcParams[\"figure.figsize\"] = [3.0, 3.0]\n",
        "    # plt.rcParams['figure.dpi'] = 80\n",
        "    plt.rcParams[\"savefig.dpi\"] = 600\n",
        "    plt.rcParams[\"savefig.format\"] = \"svg\"  # eps\n",
        "    plt.rcParams[\"savefig.transparent\"] = True\n",
        "    plt.rcParams[\"svg.fonttype\"] = \"none\"\n",
        "    # plt.rcParams['figure.edgecolor'] = 'black'\n",
        "\n",
        "    # ---------------------------- LINEWIDTH ---------------------------- #\n",
        "    plt.rcParams[\"lines.linewidth\"] = 1.3\n",
        "    plt.rcParams[\"lines.scale_dashes\"] = True\n",
        "\n",
        "    # ---------------------------- LEGEND ---------------------------- #\n",
        "    plt.rcParams[\"legend.loc\"] = \"best\"\n",
        "    plt.rcParams[\"legend.fontsize\"] = plt.rcParams[\"font.size\"]\n",
        "    plt.rcParams[\"legend.framealpha\"] = None\n",
        "    plt.rcParams[\"legend.borderpad\"] = 0.2\n",
        "    plt.rcParams[\"legend.facecolor\"] = \"inherit\"\n",
        "    # plt.rcParams['legend.edgecolor'] = 0.0\n",
        "\n",
        "    # ---------------------------- AXES ---------------------------- #\n",
        "    plt.rcParams[\"axes.titleweight\"] = 300\n",
        "    plt.rcParams[\"axes.labelsize\"] = plt.rcParams[\"font.size\"]\n",
        "    plt.rcParams[\"axes.labelweight\"] = 300\n",
        "    plt.rcParams[\"axes.labelweight\"] = \"normal\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 1.5\n",
        "\n",
        "    plt.rcParams[\"font.weight\"] = \"normal\"\n",
        "\n",
        "    # ---------------------------- TICKS ----------------------------#\n",
        "    plt.rcParams[\"xtick.top\"] = True\n",
        "    plt.rcParams[\"xtick.major.size\"] = 7\n",
        "    plt.rcParams[\"xtick.minor.size\"] = 4\n",
        "    plt.rcParams[\"xtick.major.width\"] = 1.5\n",
        "    plt.rcParams[\"xtick.minor.width\"] = 1\n",
        "    plt.rcParams[\"xtick.labelsize\"] = plt.rcParams[\"font.size\"]\n",
        "    plt.rcParams[\"xtick.direction\"] = \"in\"\n",
        "    plt.rcParams[\"xtick.minor.visible\"] = True\n",
        "\n",
        "    plt.rcParams[\"ytick.right\"] = True\n",
        "    plt.rcParams[\"ytick.major.size\"] = 7\n",
        "    plt.rcParams[\"ytick.minor.size\"] = 4\n",
        "    plt.rcParams[\"ytick.major.width\"] = 1.5\n",
        "    plt.rcParams[\"ytick.minor.width\"] = 1\n",
        "    plt.rcParams[\"ytick.labelsize\"] = plt.rcParams[\"font.size\"]\n",
        "    plt.rcParams[\"ytick.direction\"] = \"in\"\n",
        "    plt.rcParams[\"ytick.minor.visible\"] = True\n",
        "\n",
        "    # ---------------------------- IMAGES ----------------------------#\n",
        "    plt.rcParams[\"image.aspect\"] = \"equal\"\n",
        "    plt.rcParams[\"image.cmap\"] = \"inferno\"\n",
        "    plt.rcParams[\"image.origin\"] = \"upper\"\n",
        "    plt.rcParams[\n",
        "        \"image.composite_image\"\n",
        "    ] = True  # saving a figure as a vector graphics file\n",
        "\n",
        "    plt.style.use(\"seaborn-white\")\n",
        "\n",
        "\n",
        "_plot_params()\n",
        "\n",
        "plt.close()\n",
        "\n",
        "# sns.set_context('poster')  #Everything is larger"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Gaussian fitting\n",
        "\n",
        "$$P(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-(x-\\mu)^2/(2\\sigma^2)}$$\n",
        "\n",
        "```python\n",
        "def gauss(x, aplt, mean, std_dev, offset):\n",
        "    sum = offset\n",
        "    for i in range(len(ampl)):\n",
        "        sum = sum + ampl[i]*np.exp(-(x - mean[i])**2 / (2*std_dev[i]**2))\n",
        " \n",
        "    return sum\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian fit for a single peak\n",
        "def gaus_1(x, a_1, x_1, sigma_1, offset):\n",
        "    return a_1 * np.exp(-((x - x_1) ** 2) / (2 * sigma_1 ** 2)) + offset\n",
        "\n",
        "\n",
        "# Gaussian fit for two individual peaks\n",
        "def gaus_2(x, a_1, x_1, sigma_1, offset, a_2, x_2, sigma_2):\n",
        "    return (\n",
        "        a_1 * np.exp(-((x - x_1) ** 2) / (2 * sigma_1 ** 2))\n",
        "        + a_2 * np.exp(-((x - x_2) ** 2) / (2 * sigma_2 ** 2))\n",
        "        + offset\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Pearson IV fitting\n",
        "\n",
        "$A(E)\\ =\\ \\frac{|(\\Gamma(m+\\frac{\\nu}{2}i)|^2}{\\alpha \\beta (m - \\frac{1}{2}, \\frac{1}{2})} [1 + (\\frac{E - \\lambda}{\\alpha})^2]^{-m} \\cdot exp[-\\nu \\cdot arctan(\\frac{E - \\lambda}{\\alpha})] $ \n",
        "\n",
        "The first factor of the Pearson IV distribution is the normalizing constant, which involves the complex Gamma function ($\\Gamma$) and the Beta function ($\\beta$). The parameter $\\lambda$ is the localisation parameter and represents the center of the peak, while $\\alpha$ > 0 is a scale parameter, which defines the width of the function. The parameter $\\nu$ describes the asymmetry or skewness of the function and $m$ > 1$/$2 the general shape. For $\\nu\\ =$ 0 the function is the symmetric Student’s t distribution. For $m$ = 1 the function is a skewed version of a Lorentzian, while for $m$ $\\rightarrow$ $\\infty$ the function becomes a skewed Gaussian. The scale and the shape parameters also influence the maximum of the distribution, which is given by"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def pearsonIV_1(energy, alpha, Lambda, m, nu, offset):\n",
        "    num1 = np.square(\n",
        "        np.absolute(sc.special.gamma(m + (nu / 2) * j) / (sc.special.gamma(m)))\n",
        "    )\n",
        "    den1 = alpha * sc.special.beta(m - (1 / 2), 1 / 2)\n",
        "    fact1 = num1 / den1\n",
        "    term1 = np.power(1 + np.square(((energy - Lambda) / alpha)), -m)\n",
        "    term2 = np.exp(-nu * (np.arctan((energy - Lambda) / alpha)))\n",
        "\n",
        "    return fact1 * term1 * term2 + offset\n",
        "\n",
        "\n",
        "def pearsonIV_2(energy, alpha1, Lambda1, m1, nu1, alpha2, Lambda2, m2, nu2, offset):\n",
        "    return (\n",
        "        pearsonIV_1(energy, alpha1, Lambda1, m1, nu1, 0)\n",
        "        + pearsonIV_1(energy, alpha2, Lambda2, m2, nu2, 0)\n",
        "        + offset\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}